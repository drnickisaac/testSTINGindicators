---
title: "Test STING IDM v0.5"
author: "Nick Isaac"
date: "16/02/2023"
output: html_document
---
# Introduction
In this document, we're exploring the properties of the model proposed for Minimum Viable Scheme for EU Pollinator Monitoring Scheme. In this iteration, there are two data types: pan traps and transect walks. Both data types are surveyed on the same day each year. There are `v` visits to `n` sites: both numbers can be modified. We first define the model, then simulate data using user-defined parameters. We then try to recover these parameters for one simulated dataset. There are shared between the data types for a covariate and for the detection phenology.

## Priorities for future development
In approximate order of priority:
- Zero inflated Poisson
- parameterize simulations using data from the pilot studies
- missing visits
- ignoring the phenology (even though it is important)

Second tier priority
- model the data types separately
- Multispecies
- Multi-year
- spatially-explicit
- Multi-national
- is the model equally applicable to central place foragers vs others?

# Setting up the model
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load the packages, installing where required
#required.packages <- c("nimble", "ggmcmc", "coda", "reshape2", "ggplot2")
#installedPackages <- installed.packages()
#packages.to.install <- setdiff(required.packages, installedPackages)
#  install.packages(packages.to.install)
#if(length(packages.to.install) > 0)  # can cause a crash
library(nimble)
library(ggmcmc)
library(coda)
library(ggplot2)
library(reshape2)
```

Set some global parameters
```{r SetSimPars}
nSites <- 75
nVisits <- 4
maxDate <- 250 # latest survey date. 250 = mid Sept
minDate <- 100 # earliest survey date. 10 = mid April
sim.pars <- list(alpha.s = 0, # state intercept
              beta.s = 1, # state covariate
              cov = rnorm(n = nSites),
              alpha.p = 0, # logit probability of detection per pan trap (0 = 50%)
              beta1 = 200, # date when detectability is highest
              beta2 = 30, # standard deviation of detection phenology
              Multiplier = 50, # Multiplier for counts per unit intensity. 
              phScale = 20) #
Dates <- round(array(runif(n = nSites*nVisits, min = minDate, max = maxDate), 
              dim = c(nSites, nVisits)), 0)
```

Define the model code in Nimble
```{r}
obsMod <- TRUE
modelcode <- nimbleCode({
    ######################### state model
  for (i in 1:nsite) {
    linPred[i] <- alpha.s + beta.s * cov[i]
    log(lambda[i]) <- linPred[i] 
    cloglog(psi[i]) <- linPred[i]
    z[i] ~ dbern(psi[i]) # True occupancy status
  }  
  
  ######################### state model priors
  alpha.s ~ dnorm(0, 0.0001)
  beta.s ~ dnorm(0, 0.0001)

if(obsMod){ # for debugging
  ######################### Obs model
  for (i in 1:nsite) {
    for (j in 1:nvisit) {
      
      ##### pan traps
      y1[i,j] ~ dbin(size = nT[i,j], prob = Py[i,j]) # Observed data
      Py[i,j] <- z[i] * p1[i,j]
      logit(p1[i,j]) <- alpha.p + logit(pThin[i,j])

      ##### transects 
      y2[i,j] ~ dpois(lambdaThin[i,j]) # Observed counts. Might need a NegBin here or Zero-inflated
      lambdaThin[i,j] <- Multiplier * lambda[i] * pThin[i,j]
      
      #### shared: phenology
      logit(pThin[i,j]) <- phScale * f_JD[JulDate[i,j]]
  }}
}
  ######################### Obs model priors
  phScale ~ T(dt(0, 1, 1), 0, Inf) # Half Cauchy
  alpha.p ~ dnorm(-2, 0.0001) # p1 is detection probability per pan trap at peak phenology; could replace with a logistic model
  Multiplier ~ T(dt(0, 1, 1), 0, Inf)
  
  ######################### Seasonality shared effect
  beta1 ~ dunif(100, 250) # peak detectability/activity. Constrained to fall within the field season
  beta2 ~ T(dt(0, 1, 1), 0, 500) # Half Cauchy. Stdev of phenology. At sd=500 the curve is entirely flat

  for (d in 1:365){
    f_JD[d] <- 1/((2*3.14159265359)^0.5 * beta2) * exp(-((d - (beta1))^2 / (2* beta2^2)))
    # could simplify this and evaluate only for dates in the dataset
  }
  
  #########################  derived parameters
  psi.fs <- mean(z[1:nsite])
  mu.lambda <- mean(lambda[1:nsite])
})
```

# Run Simulation
Next step is to simulate some data for that model
```{r}
# set the parameters for a simulation

mcSim <- nimbleModel(modelcode,
                     constants = list(nsite = nSites, 
                                   nvisit = nVisits,
                                   alpha.s = sim.pars$alpha.s,
                                   beta.s = sim.pars$beta.s,
                                   cov = sim.pars$cov,
                                   phScale = sim.pars$phScale,
                                   alpha.p = sim.pars$alpha.p,
                                   Multiplier = sim.pars$Multiplier,
                                   beta1 = sim.pars$beta1,
                                   beta2 = sim.pars$beta2,
                                   nT = array(data = 5, dim = c(nSites, nVisits)),
                                   JulDate = Dates
                                )
                     #inits = as.list(sim.pars)
                     )
CmcSim <- compileNimble(mcSim) # note that we compile the operational model not the code!
nodesToSim <- CmcSim$getDependencies(c("psi", "lambda"),# "p1", "pThin"),
                                           self = F, downstream = T)
#nodesToSim
CmcSim$simulate(nodesToSim)
#CmcSim$simulate()
#head(CmcSim$y1)[, 1:2]
#head(CmcSim$y2)[, 1:2]
head(CmcSim$y1)
head(CmcSim$y2)
head(with(CmcSim, cbind(lambda, psi, z)))
```

To run the simulation I've fixed the values of everything in the simulation except `y1` and `y2`.


```{r exploreModel, include=FALSE}
#CmcSim$isData('y1') # FALSE
# plot the dependencies of the model in a graph (only makes sense when the model is very simple)
#library(igraph)
#plot(mcSim$getGraph())
# Determining the nodes and variables in a model
#CmcSim$getVarNames()
#note that lifted nodes can also correspond to different parametrizations
#CmcSim$getNodeNames()
# Query the model's relationships
#CmcSim$getDependencies(c('psi'))
```


Summarise the simulated data
```{r }
occSites <- with(CmcSim, apply(cbind(y1), 1, max)>0)
(simSum  <- c(
  naiveOcc = mean(occSites),
  reportingRate = mean(with(CmcSim, y1/5)), # per pan trap
  meanCount = mean(CmcSim$y2),
  reportingRate_1 = mean(with(CmcSim, y1/5)[occSites,]), # per pan trap
  meanCount_1 = mean(CmcSim$y2[occSites,])
))
```

# Fit the model 
Now fit the model on simulated data
```{r runModel}
# step 1 create an operational from from NIMBLE/JAGS/BUGS code
model <- nimbleModel(code = modelcode, 
                     constants = list(nsite = nSites, 
                                      nvisit = nVisits,
                                      cov = sim.pars$cov,
                                      nT = array(data = 5, dim = c(nSites, nVisits)),
                                      JulDate = Dates
                     ),
                     data = list(y1 = CmcSim$y1, y2 = CmcSim$y2), 
                     inits = list(z = apply(CmcSim$y1 > 0, 1, max), 
                                  alpha.s = cloglog(simSum["naiveOcc"]),
                                  beta.s = rnorm(1, 0, 1),
                                  alpha.p = simSum["reportingRate_1"],
                                  beta1 = 180,
                                  beta2 = 50,
                                  Multiplier = 1,
                                  phScale = 1)
)
# step 2 build an MCMC object using buildMCMC(). we can add some customization here
occMCMC <- buildMCMC(model, 
                     monitors = c("mu.lambda", #"psi.fs", 
                                  'alpha.s', "beta.s",
                                  'alpha.p', "phScale","Multiplier",
                                  "beta1", "beta2"), 
                     thin = 3, 
                     useConjugacy = FALSE) # useConjugacy controls whether conjugate samplers are assigned when possible
#about 5 seconds

# step 3 before compiling the MCMC object we need to compile the model first
Cmodel <- compileNimble(model) # NJBI: I don't understand why this step is necessary
# 25 seconds (less for fewer nodes)

# now the MCMC (project = NIMBLE model already associated with a project)
CoccMCMC <- compileNimble(occMCMC, project = model)
# instantaneous

# and now we can use either $run or runMCMC() on the compiled model object.
system.time(
  runMCMC_samples <- runMCMC(CoccMCMC, nburnin = 25e3, niter = 3e4, nchains = 3, samplesAsCodaMCMC = T)
) # 17 seconds for 10K iterations with 3 visits/site
```

# Examine the model output
Plot the MCMC traces
```{r diagnoseModel, fig.height = 10, fig.width=7}
plot1 <- runMCMC_samples %>% ggs() %>% ggs_traceplot(greek = TRUE)
plot2 <- runMCMC_samples %>% ggs() %>% ggs_density(greek = TRUE)
gridExtra::grid.arrange(plot1, plot2, ncol=2)
```

The phenology parameters are not so well estimated, but the other parameters are estimated quite precisely.

Have we recovered the simulated values?
```{r}
temp <- unlist(sim.pars[!names(sim.pars) %in% "cov"])
temp2 <- data.frame(name = names(temp), simulated = temp)

pars <- as.data.frame(summary(runMCMC_samples)$statistics)
pars$name <- rownames(pars)

#pars$simulated <- unlist(sim.pars[match(rownames(pars), names(sim.pars))])

pars <- merge(temp2, pars, all=TRUE)
print(pars)
#pars[,c(ncol(pars),1:(ncol(pars)-1))]
```

It would be quite useful to have the median here as well.

Now extract the Gelman-Rubin statistic (aka Rhat)
```{r diagnostics}
# Rhat
gelman.diag(runMCMC_samples) # fails if psi.fs is included
# Autocorrelation plots
#autocorr.plot(runMCMC_samples)
```

Plot detection phenology
```{r}
beta1 <- melt(sapply(runMCMC_samples, function(x) x[,"beta1"]))$value
beta2 <- melt(sapply(runMCMC_samples, function(x) x[,"beta2"]))$value
jul_dates <- round(seq(from = 1, to = 365, length.out = 50),0)
pDet <- melt(sapply(jul_dates, function(jd){
  (1/((2*pi)^0.5 * beta2) * exp(-((jd - beta1)^2 / (2* beta2^2))))
}))

pDetSumm <- pDet %>% 
  group_by(Var2) %>%
  summarise(mean = mean(value),
            lowerCI = quantile(value, 0.025),
            upperCI = quantile(value, 0.975)
  ) %>%
  ungroup()
pDetSumm$JulDate <- jul_dates[pDetSumm$Var2]
(detPlot <- ggplot(data = pDetSumm, (aes(x=JulDate))) +
    geom_line(aes(y=mean)) +
    geom_ribbon(aes(ymin=lowerCI, ymax=upperCI), alpha=0.2) +
    theme_bw() +
    xlab("Julian Date (1 = 1st January)") +
    ylab("Detection modifier"))
```